{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExperimentCNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC6iqP6w5Ae8"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgZrvd11-mZd"
      },
      "source": [
        "img_path = 'data/pixabay_Kirgiz03.jpg'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQtZaO5c-7Pa"
      },
      "source": [
        "# Load color image \n",
        "bgr_img = cv2.imread(img_path)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "Y-8SSdnBABsB",
        "outputId": "e11b6250-f0c9-4102-8ece-169ec5c0952e"
      },
      "source": [
        "img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "if img is not None:\n",
        "  # Didn't work; do something here"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-b9a5b0935a79>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    # Didn't work; do something here\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eokppyqg_wi9"
      },
      "source": [
        "cv2.imread(r\"data/pixabay_Kirgiz03.jpg\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COhVPBBN-9Io"
      },
      "source": [
        "# Convert to grayscale\n",
        "gray_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1viX5idD-xIG"
      },
      "source": [
        "# Normalize, rescale entries to lie in [0,1]\n",
        "gray_img = gray_img.astype(\"float32\")/255\n",
        "# Plot image\n",
        "plt.imshow(gray_img, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_AsN40t-1Rb",
        "outputId": "64487549-4c14-43bd-d75f-ae5b171e376e"
      },
      "source": [
        "# defining the filters \n",
        "import numpy as np\n",
        "filter_vals = np.array([[-1, -1, 1, 1], [-1, -1, 1, 1], [-1, -1, 1, 1], [-1, -1, 1, 1]])\n",
        "print('Filter shape: ', filter_vals.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filter shape:  (4, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suounMMUAZ_Y",
        "outputId": "12d2bf5d-dc01-4213-c8cb-fb680d73bbc4"
      },
      "source": [
        "# Define four different filters, all of which are linear combinations of the `filter_vals` defined above\n",
        "filter_1 = filter_vals\n",
        "filter_2 = -filter_1\n",
        "filter_3 = filter_1.T\n",
        "filter_4 = -filter_3\n",
        "filters = np.array([filter_1, filter_2, filter_3, filter_4])\n",
        "# Print out the values of filter 1 as an example\n",
        "print('Filter 1: \\n', filter_1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filter 1: \n",
            " [[-1 -1  1  1]\n",
            " [-1 -1  1  1]\n",
            " [-1 -1  1  1]\n",
            " [-1 -1  1  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRLWfwhuAe0m",
        "outputId": "61879e7e-4d07-41bc-fd9e-337728d136e8"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "    \n",
        "# Neural network with one convolutional layer with four filters\n",
        "class Net(nn.Module):\n",
        "    \n",
        "    def __init__(self, weight):\n",
        "        super(Net, self).__init__()\n",
        "        # Initializes the weights of the convolutional layer to be the weights of the 4 defined filters\n",
        "        k_height, k_width = weight.shape[2:]\n",
        "        # Assumes there are 4 grayscale filters\n",
        "        self.conv = nn.Conv2d(1, 4, kernel_size=(k_height, k_width), bias=False)\n",
        "        self.conv.weight = torch.nn.Parameter(weight)\n",
        "def forward(self, x):\n",
        "        # Calculates the output of a convolutional layer pre- and post-activation\n",
        "        conv_x = self.conv(x)\n",
        "        activated_x = F.relu(conv_x)\n",
        "        \n",
        "        # Returns both layers\n",
        "        return conv_x, activated_x\n",
        "    \n",
        "# Instantiate the model and set the weights\n",
        "weight = torch.from_numpy(filters).unsqueeze(1).type(torch.FloatTensor)\n",
        "model = Net(weight)\n",
        "# Print out the layer in the network\n",
        "print(model)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv): Conv2d(1, 4, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUucrm30DRHA"
      },
      "source": [
        "def viz_layer(layer, n_filters= 4):\n",
        "    fig = plt.figure(figsize=(20, 20))\n",
        "    \n",
        "    for i in range(n_filters):\n",
        "        ax = fig.add_subplot(1, n_filters, i+1, xticks=[], yticks=[])\n",
        "        # Grab layer outputs\n",
        "        ax.imshow(np.squeeze(layer[0,i].data.numpy()), cmap='gray')\n",
        "        ax.set_title('Output %s' % str(i+1))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh_jubszDdQF"
      },
      "source": [
        "# Plot original image\n",
        "plt.imshow(gray_img, cmap='gray')\n",
        "# Visualize all of the filters\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "fig.subplots_adjust(left=0, right=1.5, bottom=0.8, top=1, hspace=0.05, wspace=0.05)\n",
        "for i in range(4):\n",
        "    ax = fig.add_subplot(1, 4, i+1, xticks=[], yticks=[])\n",
        "    ax.imshow(filters[i], cmap='gray')\n",
        "    ax.set_title('Filter %s' % str(i+1))\n",
        "# Convert the image into an input tensor\n",
        "gray_img_tensor = torch.from_numpy(gray_img).unsqueeze(0).unsqueeze(1)\n",
        "# Get the convolutional layer (pre and post activation)\n",
        "conv_layer, activated_layer = model(gray_img_tensor)\n",
        "# Visualize the output of a convolutional layer\n",
        "viz_layer(conv_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQqJupwhDf6D"
      },
      "source": [
        "# edge detection\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "plt.imshow(gray, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo62tu2fDreR"
      },
      "source": [
        "# 3x3 array for edge detection\n",
        "sobel_y = np.array([[ -1, -2, -1], \n",
        "                   [ 0, 0, 0], \n",
        "                   [ 1, 2, 1]])\n",
        "sobel_x = np.array([[ -1, 0, 1], \n",
        "                   [ 0, 0, 0], \n",
        "                   [ 1, 2, 1]])\n",
        "  \n",
        "filtered_image = cv2.filter2D(gray, -1, sobel_y)\n",
        "plt.imshow(filtered_image, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sghYAEh1ETo1"
      },
      "source": [
        "viz_layer(activated_layer)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}